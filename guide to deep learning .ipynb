{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835af293",
   "metadata": {},
   "source": [
    "# هذه خطوة تعليمية للمبتدئين في مجال التعلم العميق "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415e35d",
   "metadata": {},
   "source": [
    "##  سنحاول استخدام كود بسيط من خلال PyTorch  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0c239",
   "metadata": {},
   "source": [
    "### الهدف من هذا الكود هو اعطائك معرفة أساسيه ب pyTorch وآلية عمل الشبكات العصبية و التعلم العميق وأهدف في نهاية هذا الكود أن تعرف المبادئ البيسطة لكل من التعلم العميق والشبكات العصبية "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9064a",
   "metadata": {},
   "source": [
    "#### أن أول شئ تحتاجه هو تنصيب PyTroch على جهازك لتتمكن من استخدامه \n",
    "#### في لبداية ستحتاج برنامج Anaconda وبعدها تكتب هذا الأمر "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf3529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa2625",
   "metadata": {},
   "source": [
    "###### لتستخدم PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35deea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "## The usual imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "## print out the pytorch version used\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a283de",
   "metadata": {},
   "source": [
    "### الآن سنكتب البيانات البسيطة والتي سنستخدمها خلال هذه المرحلة التبسيطية "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4687516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## our data in tensor form\n",
    "x = torch.tensor([[-1.0],  [0.0], [1.0], [2.0], [3.0], [4.0]], dtype=torch.float)\n",
    "y = torch.tensor([[-3.0], [-1.0], [1.0], [3.0], [5.0], [7.0]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "620b3aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print size of the input tensor\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5bb9f",
   "metadata": {},
   "source": [
    "## The Neural Network Components\n",
    "As said earlier, we are going to first define and build out the components of our neural network before training the model.\n",
    "\n",
    "### Model\n",
    "\n",
    "Typically, when building a neural network model, we define the layers and weights which form the basic components of the model. Below we show an example of how to define a hidden layer named `layer1` with size `(1, 1)`. For the purpose of this tutorial, we won't explicitly define the `weights` and allow the built-in functions provided by PyTorch to handle that part for us. By the way, the `nn.Linear(...)` function applies a linear transformation ($y = xA^T + b$) to the data that was provided as its input. We ignore the bias for now by setting `bias=False`.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f46eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural network with 1 hidden layer\n",
    "layer1 = nn.Linear(1,1, bias=False)\n",
    "model = nn.Sequential(layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775cd873",
   "metadata": {},
   "source": [
    "### Loss and Optimizer\n",
    "The loss function, `nn.MSELoss()`, is in charge of letting the model know how good it has learned the relationship between the input and output. The optimizer (in this case an `SGD`) primary role is to minimize or lower that loss value as it tunes its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7182757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "## optimizer algorithm\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7365310",
   "metadata": {},
   "source": [
    "## الآن مرحلة تدريب النموذج "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8337a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hesham.DESKTOP-09QSUFK\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:154: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 29.0051\n",
      "Epoch: 1 | Loss: 23.4311\n",
      "Epoch: 2 | Loss: 18.9495\n",
      "Epoch: 3 | Loss: 15.3463\n",
      "Epoch: 4 | Loss: 12.4492\n",
      "Epoch: 5 | Loss: 10.1199\n",
      "Epoch: 6 | Loss: 8.2472\n",
      "Epoch: 7 | Loss: 6.7415\n",
      "Epoch: 8 | Loss: 5.5308\n",
      "Epoch: 9 | Loss: 4.5575\n",
      "Epoch: 10 | Loss: 3.7749\n",
      "Epoch: 11 | Loss: 3.1457\n",
      "Epoch: 12 | Loss: 2.6398\n",
      "Epoch: 13 | Loss: 2.2331\n",
      "Epoch: 14 | Loss: 1.9061\n",
      "Epoch: 15 | Loss: 1.6431\n",
      "Epoch: 16 | Loss: 1.4317\n",
      "Epoch: 17 | Loss: 1.2618\n",
      "Epoch: 18 | Loss: 1.1251\n",
      "Epoch: 19 | Loss: 1.0152\n",
      "Epoch: 20 | Loss: 0.9269\n",
      "Epoch: 21 | Loss: 0.8559\n",
      "Epoch: 22 | Loss: 0.7988\n",
      "Epoch: 23 | Loss: 0.7529\n",
      "Epoch: 24 | Loss: 0.7160\n",
      "Epoch: 25 | Loss: 0.6863\n",
      "Epoch: 26 | Loss: 0.6624\n",
      "Epoch: 27 | Loss: 0.6432\n",
      "Epoch: 28 | Loss: 0.6278\n",
      "Epoch: 29 | Loss: 0.6154\n",
      "Epoch: 30 | Loss: 0.6054\n",
      "Epoch: 31 | Loss: 0.5974\n",
      "Epoch: 32 | Loss: 0.5910\n",
      "Epoch: 33 | Loss: 0.5858\n",
      "Epoch: 34 | Loss: 0.5816\n",
      "Epoch: 35 | Loss: 0.5783\n",
      "Epoch: 36 | Loss: 0.5756\n",
      "Epoch: 37 | Loss: 0.5734\n",
      "Epoch: 38 | Loss: 0.5717\n",
      "Epoch: 39 | Loss: 0.5703\n",
      "Epoch: 40 | Loss: 0.5691\n",
      "Epoch: 41 | Loss: 0.5682\n",
      "Epoch: 42 | Loss: 0.5675\n",
      "Epoch: 43 | Loss: 0.5669\n",
      "Epoch: 44 | Loss: 0.5664\n",
      "Epoch: 45 | Loss: 0.5661\n",
      "Epoch: 46 | Loss: 0.5658\n",
      "Epoch: 47 | Loss: 0.5655\n",
      "Epoch: 48 | Loss: 0.5653\n",
      "Epoch: 49 | Loss: 0.5652\n",
      "Epoch: 50 | Loss: 0.5650\n",
      "Epoch: 51 | Loss: 0.5649\n",
      "Epoch: 52 | Loss: 0.5649\n",
      "Epoch: 53 | Loss: 0.5648\n",
      "Epoch: 54 | Loss: 0.5647\n",
      "Epoch: 55 | Loss: 0.5647\n",
      "Epoch: 56 | Loss: 0.5647\n",
      "Epoch: 57 | Loss: 0.5646\n",
      "Epoch: 58 | Loss: 0.5646\n",
      "Epoch: 59 | Loss: 0.5646\n",
      "Epoch: 60 | Loss: 0.5646\n",
      "Epoch: 61 | Loss: 0.5646\n",
      "Epoch: 62 | Loss: 0.5646\n",
      "Epoch: 63 | Loss: 0.5645\n",
      "Epoch: 64 | Loss: 0.5645\n",
      "Epoch: 65 | Loss: 0.5645\n",
      "Epoch: 66 | Loss: 0.5645\n",
      "Epoch: 67 | Loss: 0.5645\n",
      "Epoch: 68 | Loss: 0.5645\n",
      "Epoch: 69 | Loss: 0.5645\n",
      "Epoch: 70 | Loss: 0.5645\n",
      "Epoch: 71 | Loss: 0.5645\n",
      "Epoch: 72 | Loss: 0.5645\n",
      "Epoch: 73 | Loss: 0.5645\n",
      "Epoch: 74 | Loss: 0.5645\n",
      "Epoch: 75 | Loss: 0.5645\n",
      "Epoch: 76 | Loss: 0.5645\n",
      "Epoch: 77 | Loss: 0.5645\n",
      "Epoch: 78 | Loss: 0.5645\n",
      "Epoch: 79 | Loss: 0.5645\n",
      "Epoch: 80 | Loss: 0.5645\n",
      "Epoch: 81 | Loss: 0.5645\n",
      "Epoch: 82 | Loss: 0.5645\n",
      "Epoch: 83 | Loss: 0.5645\n",
      "Epoch: 84 | Loss: 0.5645\n",
      "Epoch: 85 | Loss: 0.5645\n",
      "Epoch: 86 | Loss: 0.5645\n",
      "Epoch: 87 | Loss: 0.5645\n",
      "Epoch: 88 | Loss: 0.5645\n",
      "Epoch: 89 | Loss: 0.5645\n",
      "Epoch: 90 | Loss: 0.5645\n",
      "Epoch: 91 | Loss: 0.5645\n",
      "Epoch: 92 | Loss: 0.5645\n",
      "Epoch: 93 | Loss: 0.5645\n",
      "Epoch: 94 | Loss: 0.5645\n",
      "Epoch: 95 | Loss: 0.5645\n",
      "Epoch: 96 | Loss: 0.5645\n",
      "Epoch: 97 | Loss: 0.5645\n",
      "Epoch: 98 | Loss: 0.5645\n",
      "Epoch: 99 | Loss: 0.5645\n",
      "Epoch: 100 | Loss: 0.5645\n",
      "Epoch: 101 | Loss: 0.5645\n",
      "Epoch: 102 | Loss: 0.5645\n",
      "Epoch: 103 | Loss: 0.5645\n",
      "Epoch: 104 | Loss: 0.5645\n",
      "Epoch: 105 | Loss: 0.5645\n",
      "Epoch: 106 | Loss: 0.5645\n",
      "Epoch: 107 | Loss: 0.5645\n",
      "Epoch: 108 | Loss: 0.5645\n",
      "Epoch: 109 | Loss: 0.5645\n",
      "Epoch: 110 | Loss: 0.5645\n",
      "Epoch: 111 | Loss: 0.5645\n",
      "Epoch: 112 | Loss: 0.5645\n",
      "Epoch: 113 | Loss: 0.5645\n",
      "Epoch: 114 | Loss: 0.5645\n",
      "Epoch: 115 | Loss: 0.5645\n",
      "Epoch: 116 | Loss: 0.5645\n",
      "Epoch: 117 | Loss: 0.5645\n",
      "Epoch: 118 | Loss: 0.5645\n",
      "Epoch: 119 | Loss: 0.5645\n",
      "Epoch: 120 | Loss: 0.5645\n",
      "Epoch: 121 | Loss: 0.5645\n",
      "Epoch: 122 | Loss: 0.5645\n",
      "Epoch: 123 | Loss: 0.5645\n",
      "Epoch: 124 | Loss: 0.5645\n",
      "Epoch: 125 | Loss: 0.5645\n",
      "Epoch: 126 | Loss: 0.5645\n",
      "Epoch: 127 | Loss: 0.5645\n",
      "Epoch: 128 | Loss: 0.5645\n",
      "Epoch: 129 | Loss: 0.5645\n",
      "Epoch: 130 | Loss: 0.5645\n",
      "Epoch: 131 | Loss: 0.5645\n",
      "Epoch: 132 | Loss: 0.5645\n",
      "Epoch: 133 | Loss: 0.5645\n",
      "Epoch: 134 | Loss: 0.5645\n",
      "Epoch: 135 | Loss: 0.5645\n",
      "Epoch: 136 | Loss: 0.5645\n",
      "Epoch: 137 | Loss: 0.5645\n",
      "Epoch: 138 | Loss: 0.5645\n",
      "Epoch: 139 | Loss: 0.5645\n",
      "Epoch: 140 | Loss: 0.5645\n",
      "Epoch: 141 | Loss: 0.5645\n",
      "Epoch: 142 | Loss: 0.5645\n",
      "Epoch: 143 | Loss: 0.5645\n",
      "Epoch: 144 | Loss: 0.5645\n",
      "Epoch: 145 | Loss: 0.5645\n",
      "Epoch: 146 | Loss: 0.5645\n",
      "Epoch: 147 | Loss: 0.5645\n",
      "Epoch: 148 | Loss: 0.5645\n",
      "Epoch: 149 | Loss: 0.5645\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "for ITER in range(150):\n",
    "    model = model.train()\n",
    "\n",
    "    ## forward\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    ## backward + update model params \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    print('Epoch: %d | Loss: %.4f' %(ITER, loss.detach().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafaf743",
   "metadata": {},
   "source": [
    "## مرحلة اختبار النموذج "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65215cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.096769332885742\n"
     ]
    }
   ],
   "source": [
    "## test the model\n",
    "sample = torch.tensor([10.0], dtype=torch.float)\n",
    "predicted = model(sample)\n",
    "print(predicted.detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ebb4ef",
   "metadata": {},
   "source": [
    "# في النهاية أود تهنئتك لقد قمت ببناء نموذج للشبكات العصبية "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4439bbcd",
   "metadata": {},
   "source": [
    "## بقي أمر واحد هل يمكنك التعديل على هذا النموذج لاضافة عناصراخرى وجعله أكبر وأكثر تعقيدا ؟ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45217293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
